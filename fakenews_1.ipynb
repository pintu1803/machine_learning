{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fakenews_1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1PBdH-W2IvRfrCEhp9H9lvtCb7_8GbCOt",
      "authorship_tag": "ABX9TyMnNHNhgbRnOhO5TTBEqLOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pintu1803/machine_learning/blob/main/fakenews_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef5U6sEYE6OD"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J7M0QVcEuS0"
      },
      "source": [
        "#22/02/2021\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "train_raw_data=pd.read_csv('/content/drive/MyDrive/fake-news/train.csv')\n",
        "train_raw_data=train_raw_data.dropna()\n",
        "\n",
        "x=train_raw_data['text'].values\n",
        "y=train_raw_data['label'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=1000)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2aXn8RvF9f4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer                    \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=50000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "# Adding 1 because of  reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1                          \n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbKGjUIHHpfG",
        "outputId": "fd0fbec6-dbdc-4d32-ef61-98e1b39ebc3e"
      },
      "source": [
        "print(type(x_train))\n",
        "for row in x_train:\n",
        "  print(row)\n",
        "  break"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[  483  4504 15579  5486     4  8301  9912   338    11  4730     4    45\n",
            "  2225   145 42938   263    15   116  5018     1  2339    35     9     5\n",
            "   219   954    19   274    35     2     1   596    11     1   117  1399\n",
            "  1451    62    40   338  2258   926  4791  5844     1   133   126   486\n",
            "   361 23497   152  1000    32   266    55    68   122  1049     2   755\n",
            "     1   739   948    42    22   706     3    50   367     1   147    32\n",
            "    20   984  2208     2   148     1    89   990  6297   517     9     1\n",
            "    91    78    10    23  5844   278   129  1864     1    68    42    22\n",
            "    45     3    71    10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQNrtGNeJnyq",
        "outputId": "32f56ab7-a689-449d-cbcd-8b81b83073be"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-21 19:13:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-03-21 19:13:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-03-21 19:13:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 41s  \n",
            "\n",
            "2021-03-21 19:16:09 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F9J3x0ILtBh",
        "outputId": "c4b19fd2-38e7-48ad-d86f-abe50b8ae489"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uENb_T8uLyds",
        "outputId": "a2ddffe5-571c-4198-fccf-b4dcddcf5e3a"
      },
      "source": [
        "# !ls\n",
        "# !pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.200d.txt  glove.6B.50d.txt\tsample_data\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OSx6xZAGkmk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "  \n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_dim = 50\n",
        "embedding_matrix = create_embedding_matrix('/content/glove.6B.300d.txt',\n",
        "                                            tokenizer.word_index,  \n",
        "                                            embedding_dim)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVflAZZRMkqB",
        "outputId": "a670cb4a-ae65-4dba-875c-81e053927326"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    batch_size=10)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1372/1372 [==============================] - 258s 164ms/step - loss: 0.3753 - accuracy: 0.7985 - val_loss: 0.1852 - val_accuracy: 0.9243\n",
            "Epoch 2/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 0.0652 - accuracy: 0.9778 - val_loss: 0.2212 - val_accuracy: 0.9134\n",
            "Epoch 3/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.2459 - val_accuracy: 0.9232\n",
            "Epoch 4/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2685 - val_accuracy: 0.9241\n",
            "Epoch 5/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2830 - val_accuracy: 0.9248\n",
            "Epoch 6/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 5.8763e-05 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9217\n",
            "Epoch 7/10\n",
            "1372/1372 [==============================] - 225s 164ms/step - loss: 5.8099e-04 - accuracy: 0.9999 - val_loss: 0.3121 - val_accuracy: 0.9230\n",
            "Epoch 8/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 5.2005e-04 - accuracy: 0.9999 - val_loss: 0.3127 - val_accuracy: 0.9232\n",
            "Epoch 9/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3380 - val_accuracy: 0.9248\n",
            "Epoch 10/10\n",
            "1372/1372 [==============================] - 224s 163ms/step - loss: 4.0857e-04 - accuracy: 0.9999 - val_loss: 0.3700 - val_accuracy: 0.9234\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          18314500  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 18,379,929\n",
            "Trainable params: 18,379,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS80QkuRX8ce",
        "outputId": "7137493a-d260-47f5-f4c9-24524c7ad3e8"
      },
      "source": [
        "val_loss, val_acc=model.evaluate(x_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.9234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH4KhWghYQXF",
        "outputId": "9b794431-f5f5-45aa-83f2-57ec0b191ddf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred=model.predict(x_test)\n",
        "y_pred=[np.argmax(x) for x in y_pred]\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "cr=classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion matrix=\\n\",cm)\n",
        "print(\"Classification report=\\n\",cr)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix=\n",
            " [[2565    0]\n",
            " [2007    0]]\n",
            "Classification report=\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72      2565\n",
            "           1       0.00      0.00      0.00      2007\n",
            "\n",
            "    accuracy                           0.56      4572\n",
            "   macro avg       0.28      0.50      0.36      4572\n",
            "weighted avg       0.31      0.56      0.40      4572\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}